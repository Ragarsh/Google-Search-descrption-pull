{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"st\">11Open submenu (Data)Data; 9Open submenu (Media)Media &middot; WCL &middot; <br />\n",
       " Resources; 9Open submenu (About Us)About Us. Close submenu (Data)Data.</span>]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "sys.path.append('/Applications/Data/anaconda/pkgs/requests-2.13.0-py27_0/lib/python2.7/site-packages')\n",
    "\n",
    "import requests\n",
    "from BeautifulSoup import BeautifulSoup\n",
    "Soup = BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import urllib2\n",
    "import time\n",
    "import collections\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from random import randint\n",
    "\n",
    "#www.google.com/search?q=%s\n",
    "\n",
    "def google_scraper(search):\n",
    "    address=\"https://www.google.com/search?q=%s\" %(search)\n",
    "    r = requests.get(address)\n",
    "    resp = r.content\n",
    "    soup = BeautifulSoup(resp.decode('utf-8', 'ignore'))   \n",
    "    x = soup.findAll('span', attrs={'class':'st'})\n",
    "    y = x[:1]\n",
    "    return y\n",
    "\n",
    "#google_scraper(\"advisenltd.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Media_list = pd.read_excel('NFP-Tiers.xlsx')\n",
    "#Media_list['Outlet URL'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url_desc = []\n",
    "\n",
    "#rand_result = randint(1,10)\n",
    "rand_time = randint(60)\n",
    "\n",
    "for i in range (136,556):\n",
    "    url = Media_list['Outlet URL'][i]\n",
    "    desc = google_scraper(url)\n",
    "    desc_str = str(desc)\n",
    "    url_desc.append(desc_str)\n",
    "    if i%5 == 0:\n",
    "        time.sleep(rand_time)\n",
    "\n",
    "escript = pd.DataFrame()\n",
    "df = Descript.append(url_desc)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('NFPdescriptions.xlsx', engine = 'xlsxwriter')\n",
    "df.to_excel(writer, sheet_name = 'Descriptions')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "words  = []\n",
    "strings = []\n",
    "desc = pd.read_excel('NFPdescriptions1.xlsx')\n",
    "\n",
    "#cleansup url descrioptions and pulls out the nouns\n",
    "\n",
    "\n",
    "for i in range(0,135):\n",
    "    string = str(desc[0][i])\n",
    "    string1 = (re.sub('<.+?>', '', string))\n",
    "    string2 = (re.sub('&middot;', '', string1))\n",
    "    string3 = (re.sub('&amp;', '', string2))\n",
    "    string4 = (re.sub('&nbsp;', '', string3))\n",
    "    string5 = (re.sub('[A-Z0-9].*com', '', string4))\n",
    "    #string6 = (re.sub('...', '', string5))\n",
    "    #string7 = (re.sub('[A-Z0-9].*org','', string6))\n",
    "    #string8 = (re.sub('[A-Z0-9]+\\.[A-Z]', '', string7))\n",
    "    string6 = (re.sub('&#39', '', string5))\n",
    "    strings.append(string6)\n",
    "\n",
    "for i in range(0,135):    \n",
    "    desc_df = pd.DataFrame(strings)\n",
    "    a = desc_df[0][i].split()\n",
    "    words.append(a)\n",
    "\n",
    "#count = []    \n",
    "#for x in range(0,52):\n",
    "#    c1 = Counter(words[x])\n",
    "#    count.append(c1)\n",
    "\n",
    "#nouns = []   \n",
    "#for j in range(0,135):\n",
    "#    tagged = nltk.pos_tag(words[j])\n",
    "#    noun = [word for word, pos in tagged if pos == 'PRT']\n",
    "#    nouns.append(noun)\n",
    "    #count[1]\n",
    "    #return nouns\n",
    "\n",
    "#cleansup = []\n",
    "#cleansup.append(cleanup(desc))\n",
    "#cleansup\n",
    "#words\n",
    "\n",
    "if del_phrase[1] in words[0]:\n",
    "    print \"success\"\n",
    "else: print \"false\"\n",
    "    \n",
    "words\n",
    "words_df = pd.DataFrame(words)\n",
    "\n",
    "writer = pd.ExcelWriter('NFPwords1.xlsx', engine = 'xlsxwriter')\n",
    "words_df.to_excel(writer, sheet_name = 'Descriptions')\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "general = ('Breaking news', 'latest news', 'weather', 'entertainment', 'health', 'science', 'Politics', 'headlines');\n",
    "sports = ('sport', 'sports', 'scores');\n",
    "insurance = ('property and casualty', 'property', 'casualty', 'insurance', 'agents', 'brokerage', 'retirement', 'tax', 'estate planning', 'mortgage');\n",
    "finance = ('finance', 'financial', 'stock', 'risk', 'market', 'markets', 'investing', 'money');\n",
    "tech = ('tech', 'technology');\n",
    "data = ('data', 'analytics', 'analysis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag = []\n",
    "insurance_count = 0\n",
    "general_count = 0\n",
    "sports_count = 0\n",
    "finance_count = 0\n",
    "tech_count = 0\n",
    "data_count = 0\n",
    "\n",
    "for i in range (0, len(insurance)):\n",
    "    for j in range (0, 135):\n",
    "        if insurance[i] in words[j]:\n",
    "            insurance_count += 1\n",
    "\n",
    "for i in range (0, len(finance)):\n",
    "    for j in range (0, 135):\n",
    "        if finance[i] in words[j]:\n",
    "            finance_count += 1\n",
    "            \n",
    "for i in range (0, len(general)):\n",
    "    for j in range (0, 135):\n",
    "        if general[i] in words[j]:\n",
    "            general_count += 1\n",
    "            \n",
    "for i in range (0, len(sports)):\n",
    "    for j in range (0, 135):\n",
    "        if sports[i] in words[j]:\n",
    "            sports_count += 1\n",
    "            \n",
    "for i in range (0, len(tech)):\n",
    "    for j in range (0, 135):\n",
    "        if tech[i] in words[j]:\n",
    "            tech_count += 1\n",
    "            \n",
    "for i in range (0, len(data)):\n",
    "    for j in range (0, 135):\n",
    "        if data[i] in words[j]:\n",
    "            data_count += 1\n",
    "\n",
    "tag.append(insurance_count) \n",
    "tag.append(finance_count)\n",
    "tag.append(general_count)\n",
    "tag.append(sports_count)\n",
    "tag.append(tech_count)\n",
    "tag.append(data_count)\n",
    "\n",
    "tag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
